{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d52186",
   "metadata": {},
   "source": [
    "# Welcome to the Data Manipulation Lesson.\n",
    "## Notebook 1\n",
    "\n",
    "In this lesson, we will be using this workbook in tandum with the reading assignments.\n",
    "\n",
    "The workbook has been broken up into three sections.  Each section has reading assignments and is followed by questions and prompts for you to work through.\n",
    "\n",
    "In [your Canvas](https://launchcode.instructure.com/courses/14/quizzes/569), you will find the reading quiz.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b781c5c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52e3ea6ce138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"titanic new.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic new.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data= pd.read_csv(\"titanic new.csv\")++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a701fe6",
   "metadata": {},
   "source": [
    "## Before You Get Started\n",
    "\n",
    "We are going to be using the Titanic Dataset. Make sure to run a head() before you start working with manipulation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the head of your data set here:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35eb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are, go ahead and drop them:\n",
    "\n",
    "# Lets talk about this!\n",
    "# There are duplicate rows\n",
    "# ... but do they actually represent the same person?\n",
    "\n",
    "# Unlike the other Titanic data set, this file doesn't have Passenger ID or Name\n",
    "# There's nothing to distinguish one 21 year old male from another if they have the same ticket & passage\n",
    "# From the other data set (or research) we know there are 891 unique passengers represented\n",
    "# Let's check the row count\n",
    "data.shape\n",
    "# There are 891 rows! One for each passenger, even though some are identical.\n",
    "# On principal I will not de-dupe\n",
    "# This is why keys are so important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70caa2",
   "metadata": {},
   "source": [
    "### Cleaning Note:\n",
    "\n",
    "While the columns are not the \"prettiest\", don't adjust any of them yet. We are going to update some values and add some values as we workthrough this notebook. Applologies for the extra visual \"noise\" on your screen. You will be given the option to tidy up the columns at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11789dff",
   "metadata": {},
   "source": [
    "## Running Tables Note:  \n",
    "If your tables don't appear to have accepted your changes, try the \"Run All\" option in the \"Cell\" section of the menu bar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4104f7d",
   "metadata": {},
   "source": [
    "<span style=\"background-color:dodgerblue; color:dodgerblue;\">- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948036e",
   "metadata": {},
   "source": [
    "# A. Aggregation\n",
    "\n",
    "1. Please read the following:\n",
    "    - [Python | Pandas dataframe.aggregate()](https://www.geeksforgeeks.org/python-pandas-dataframe-aggregate/)\n",
    "    - [Python | Pandas dataframe.groupby()](https://www.geeksforgeeks.org/python-pandas-dataframe-groupby/)\n",
    "1. Answer the Check Your Understanding Questions in your Canvas account.\n",
    "1. Work through the section Exercises.  \n",
    "    - There are 4 sections in part A:\n",
    "        - Groupby\n",
    "        - Aggregation Methods\n",
    "        - Groupby and Basic Math\n",
    "        - Groupby and Multiple Aggregations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116d353",
   "metadata": {},
   "source": [
    "#### Creating Variables.\n",
    "\n",
    "As we begin to manipulate our data, create new variables to store your work in.  This will keep your original data in tact.  Having the original dataset available will save you time with each manipulation.  You can also create variable names that inform you of the purpose of the manipulation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0621dc21",
   "metadata": {},
   "source": [
    "### 1: Groupby <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89219ea",
   "metadata": {},
   "source": [
    "#### Groupby \"embark_town\"\n",
    "\n",
    "1. Using the titanic data set, groupby \"embark_town\".\n",
    "1. Create a variable that will represent the grouping of data. \n",
    "1. Intitalize it using the groupby() function and pass it the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34322f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your groupby \"embark_town\" here:\n",
    "embark_group = data.groupby('embark_town')\n",
    "# whenever we call embark_group it will execute the groupby function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the grouped data as a table, use the variable_name.first():\n",
    "embark_group.first()\n",
    "# this is running the aggregation first() on our variable\n",
    "# so we get the first line of each 'embark_town' group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc226e",
   "metadata": {},
   "source": [
    "#### Groupby \"survived\"\n",
    "\n",
    "Did you know that you can also chain on some of our exploratory methods to the groupby method?\n",
    "\n",
    "1. Create & initalize a new variable to hold a table that will groupby \"survived\" \n",
    "1. Use method chaining to tack on the describe method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9afd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your groupby \"survived\" table here:\n",
    "survived_group = data.groupby('survived')\n",
    "\n",
    "# run your table below:\n",
    "survived_group.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your table with describe\n",
    "survived_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c917d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is this table organized?  Why are there 40 columns now?\n",
    "\n",
    "# describe() runs multiple aggregations\n",
    "# so it is going column by column, giving each aggregation\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42783c6d",
   "metadata": {},
   "source": [
    "### 2. Aggregation Methods <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af74f16",
   "metadata": {},
   "source": [
    "Note: **agg()** and **aggregate()** are identical [source](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14147835",
   "metadata": {},
   "source": [
    "#### Method Chaining\n",
    "\n",
    "1. Create a variable to method chain **head()** and **agg()** togehter.\n",
    "1. Pass one of the following statistical values to **agg()**\n",
    "   - \"mean\", \"median\", \"mode\", \"min\", \"max\", \"std\", \"var\", \"first\", \"last\", \"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your method chain here:\n",
    "tops = data.head().agg('max')\n",
    "tops\n",
    "# For strings, max takes the last alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089919c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to method chain head() with agg(\"sum\")\n",
    "totals = data.head().agg('sum')\n",
    "# run your table:\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e72d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the sum table.  What is going on with the \"sex\", \"class\", and \"alive\" columns?\n",
    "\n",
    "# For strings, sum appends the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f370f65",
   "metadata": {},
   "source": [
    "#### Using a Dictionary <span style=\"color:darkorange;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "##### A dictionary is a Python collection type.  \n",
    "\n",
    "Is a collection type that stores **key-value pairs**.  A key-value pair is an orgainzation system that is made up of a single *key* that has one or more *values* paired with it.  \n",
    "Think of it like your contacts list.  The contacts list is the dictionary object.  \n",
    "Each contact is organized by a key, usually name.  And attached to each name is contact information, or the values.\n",
    "Some contacts might have email address, phone number, home or work address, etc. Other contacts may just be a name and phone number.  This is a very simple example, but understanding this orgainzational structure will be helpful as you learn to manipulate tables.  \n",
    "\n",
    "*Here is a dictionary example with 3 keys:*\n",
    ">**contacts_dictionary = {\"name1\": [\"email\", 555-5552, \"work info\"], \n",
    "      \"name2\": [\"email\", 555-5554],\n",
    "      \"name3\": 555-5555}**\n",
    "                     \n",
    "*Here is a dictionary example with a single key-value pair*\n",
    "**study_group_dictionary = {\"name1\": 555-5557}**   \n",
    "\n",
    "It has a single key, and a list of values. The organization of this structure is called a \"Key-Value Pair\".\n",
    "Using the contact list example, the key would be the name of the person and the values would be their contact information.  The key is a single item (the person's name) and the values can be a single item (an email address) or mulitple items (email, phone number, address, work info, etc).\n",
    "Keys and values can be any data type, but must use correct data type syntax.  The keys do not have to be strings, but they do need to be a single value.  \n",
    "\n",
    "For more information, you can read more on dictionary objects [here](https://www.w3schools.com/python/python_dictionaries.asp).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1059cd",
   "metadata": {},
   "source": [
    "#### Aggregation across muliple columns using dictionary functionality\n",
    "\n",
    "##### Syntax Example:\n",
    "\n",
    "**age_dictionary={\"age\":[\"sum\", \"max\"]}**\n",
    "\n",
    "We are creating a new dictionary (**age_dictionary**).  The key is **age** and the values we want are **\"sum\"\"** and **\"max\"**.  This dictionary object has now become a tempate for the aggregations we want to preform.  However, on it's own, it does nothing.  Once passed to the **agg()** method, it will pick out the specific location of data we want to examine.  Making a subset table.  \n",
    "\n",
    "The code is contained in the box below.  Run it and see what happens.\n",
    "\n",
    "\n",
    "For syntax examples, review [this webpage](https://www.geeksforgeeks.org/python-pandas-dataframe-aggregate/).\n",
    "#### <span style=\"color:coral;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89392dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the table output before you uncomment the code below.\n",
    "# total and max ages from data\n",
    "age_dictionary = {\"age\":[\"sum\", \"max\"]}\n",
    "dictionary_agg = data.agg(age_dictionary)\n",
    "dictionary_agg\n",
    "\n",
    "# By using a dictionary we can keep the program from going through each column\n",
    "# Think of survived_group.describe() and how hard it was to read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e1283b",
   "metadata": {},
   "source": [
    "1. What if we want to look at more than one column at a time?  We pass more dictionaries to the agg function.\n",
    "1. Create a variable to hold at least 3 columns.  Use the syntax from the \"Syntax Example\" as a guide.\n",
    "    - Aggregate the following:  survived: \"sum\" & \"count\"; age: \"std\" & \"min\", and sibsp: \"count\" & \"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your dictionary here:\n",
    "\n",
    "new_dictionary = {\"age\":[\"std\", \"min\"],\n",
    "                 \"survived\":[\"sum\", \"count\"],\n",
    "                 \"sibsp\":[\"count\", \"sum\"]}\n",
    "data.agg(new_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d7169",
   "metadata": {},
   "source": [
    "### 3. Groupby and Basic Math <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "\n",
    "1. Groupby \"pclass\".  Make sure you use a variable to hold your grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac154abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4a78be7c0ddb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Code your groupby here:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclass_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Run your table using first() here instead of head():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Code your groupby here:\n",
    "\n",
    "class_group = data.groupby('pclass')\n",
    "\n",
    "# Run your table using first() here instead of head():\n",
    "class_group.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8a0be",
   "metadata": {},
   "source": [
    "### 4. Groupby and Multiple Aggregations <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b74e40",
   "metadata": {},
   "source": [
    "#### Group with a List<span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1655c",
   "metadata": {},
   "source": [
    "1. We want to do muliple aggregation functions to our newly grouped data set.  We created a variable to hold a list of functions we want to perform.  These functions are part of the agg method.  When we pass our list to the method, the method will iterate through each item and perform that function for the entire table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our list of functions\n",
    "agg_func_list = ['sum', 'mean', 'median', 'min', 'max', 'std', 'var', 'first', 'last', 'count']\n",
    "\n",
    "\n",
    "#Apply the agg method to our passenger_class variable (made in the Groupby Basic Math section).  \n",
    "# Pass our list to the function and run your table.\n",
    "\n",
    "class_group.agg(agg_func_list)\n",
    "# This acts like .describe() but we control the aggregations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734b183",
   "metadata": {},
   "source": [
    "#### Group with a Dictionary<span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span>\n",
    "\n",
    "Using only a list provides us with the entire table.  What if we only want to look at age vs pclass?  \n",
    "\n",
    "we can create a dictionary to hold the age column for us.  The *key* would be the name of our column, and the values our list of functions to preform on that column.  The code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_dict = {\n",
    "    'age':\n",
    "    ['sum', 'mean', 'median', 'min', 'max', 'std', 'var', 'first', 'last', 'count']\n",
    "}\n",
    "# We would run our table like this:\n",
    "# passenger_class.agg(agg_func_dict)  \n",
    "\n",
    "# The dictionary is a set of instructions passed to .agg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b17b5f",
   "metadata": {},
   "source": [
    "Looking at the *age_func_dict* syntax, create a dictionary variable for the \"survived\" column and pass it to **passenger_class.agg()** in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b05656e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_group' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ddb327e28bd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'var'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclass_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurvived_func_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Here we're passing the survived_func_dict instructions to .agg()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_group' is not defined"
     ]
    }
   ],
   "source": [
    "# Code it here:\n",
    "survived_func_dict = {\n",
    "    'survived':\n",
    "    ['sum', 'mean', 'median', 'min', 'max', 'std', 'var', 'first', 'last', 'count']\n",
    "}\n",
    "class_group.agg(survived_func_dict)\n",
    "\n",
    "# Here we're passing the survived_func_dict instructions to .agg()\n",
    "# and performing .agg() within each class_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a224518",
   "metadata": {},
   "source": [
    "<span style=\"background-color:dodgerblue; color:dodgerblue;\">- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e825467",
   "metadata": {},
   "source": [
    "# B. Recoding and Creating New Values and Variables \n",
    "\n",
    "1. Please read the following:\n",
    "    1. [How to create new columns derived from existing columns?](https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html)\n",
    "    1.[Recode Data](https://pythonfordatascienceorg.wordpress.com/recode-data/)\n",
    "1. Answer the Check Your Understanding questions in your Canvas Account.\n",
    "1. Work through the Part B, there are 2 sections\n",
    "\n",
    "Suggested Reading:\n",
    "- [How to manipulate textual data?](https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f6c33",
   "metadata": {},
   "source": [
    "### Create a New Column <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "As questions arrise during your data exploring and cleaning, you might want to test them out.  In this instance, we want to make sure the values we want to manipulate remain untouched. One thing we can do is to add a new column that will contain our manipulations.\n",
    "\n",
    "In the box below:\n",
    "1. Create a new column by manipulating the values of different column.  Specifically, create a new column, \"fare_2021\" that allows us to compare the cost of fare in pounds back in 1912 to 2021.  [This website](https://www.in2013dollars.com/uk/inflation/1912) can help you find the 2021 fare amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d521795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your new \"fare_2021\" column here:\n",
    "data['fare_2021'] = data['fare']*119.9592\n",
    "# Run the head of your table to see your new column:\n",
    "data.head()\n",
    "\n",
    "# running data['fare']*120 will list each value in the fare column multiplied by 120\n",
    "# This section  data['fare_2021'] =    builds a new column and records the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944618b",
   "metadata": {},
   "source": [
    "### Replacing Values <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    " \n",
    "Replace the values in the \"alive\" coloum from string \"yes\" or \"no\" to bools, where \"yes\" becomes True and \"no\" becomes False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa29ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your updated values here:\n",
    "data['alive2'] = data['alive'].replace({'yes':True, 'no':False})\n",
    "data.head()\n",
    "\n",
    "# I'm recording this in a new column to avoid overwriting 'alive' so that we can reference it in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d7e60",
   "metadata": {},
   "source": [
    "We can also use functions to update values.\n",
    "\n",
    "1. Create a function that will set the alive values as bools. Apply it to your table and run your table here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your function here:\n",
    "def alive_bool(value):\n",
    "    return value == 'yes'\n",
    "\n",
    "data['alive3'] = data['alive'].apply(alive_bool)\n",
    "data.head()\n",
    "\n",
    "# .apply() runs our function alive_bool() on each data['alive'] value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a830345",
   "metadata": {},
   "source": [
    "### Using a function to create a new column <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "\n",
    "Sometimes you might want to create a new column based on combining multiple columns together.\n",
    "\n",
    "1. create an \"age_group\" column that breaks years up as 0-19, 20-29, 30-39, etc until all given ages are covered.  Make sure you check to see where you can stop counting by 10s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your max age check here:\n",
    "data.age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code the new \"age_group\" column function here:\n",
    "\n",
    "def make_age_group(value):\n",
    "    print((value.ndim))\n",
    "    pd.cut(np.array(int(value)), [0, 10, 20, 30, 40, 50, 60, 70, 80])\n",
    "\n",
    "data['age'].apply(make_age_group)\n",
    "\n",
    "# Using cut with apply is throwing an error because cut runs on a series (column) \n",
    "# while apply breaks the series out into individual values\n",
    "# and then feeds those values into the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784319c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_age_group(value):\n",
    "    if value <10:\n",
    "        return \"0-9\"\n",
    "# Now we can assume the value is at least 10\n",
    "# Anything lower is caught by the first if clause\n",
    "    elif  value < 20:\n",
    "        return \"10-19\"    \n",
    "    elif value < 30:\n",
    "        return \"20-29\"\n",
    "    elif value < 40:\n",
    "        return \"30-39\"\n",
    "    elif value < 50:\n",
    "        return \"40-49\"\n",
    "    elif value < 60:\n",
    "        return \"50-59\"\n",
    "    elif value < 70:\n",
    "        return \"60-69\"\n",
    "    elif value < 80:\n",
    "        return \"70-79\"\n",
    "    elif value < 90:\n",
    "        return \"80-89\"\n",
    "    else:\n",
    "        return \"no data\"\n",
    "    \n",
    "data[\"age_group\"] = data[\"age\"].apply(make_age_group) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64ca65",
   "metadata": {},
   "source": [
    "<span style=\"background-color:dodgerblue; color:dodgerblue;\">- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760d2ed",
   "metadata": {},
   "source": [
    "# C. Reshaping Tables\n",
    "\n",
    "1. Please read the following:\n",
    "    1. [How to reshape the layout of tables?](https://pandas.pydata.org/docs/getting_started/intro_tutorials/07_reshape_table_layout.html)\n",
    "1. Answer the Check Your Understanding in your Canvas account\n",
    "1. Work through Part C, there are 4 sections\n",
    "\n",
    "\n",
    "Suggested Reading:\n",
    "1. [pandas.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html)\n",
    "1. [pandas.melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)\n",
    "1. [pandas.pivot](https://pandas.pydata.org/docs/reference/api/pandas.pivot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ceef3",
   "metadata": {},
   "source": [
    "### Sort_values <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ddc8a",
   "metadata": {},
   "source": [
    "Use **sort_values()** to answer the following question:\n",
    "> What is the age of the person who paid the highest fare?\n",
    "\n",
    "Hint: We want to see the highest fare value first. What order would we want? ascending or descending?  Check the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html?highlight=sort_values#pandas.DataFrame.sort_values) for the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ca853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your sort_values here:\n",
    "\n",
    "# Run your table here:\n",
    "data.sort_values(by=\"age_group\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d0d2c",
   "metadata": {},
   "source": [
    "### pivot_table <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "1. pivot the table of the summed data where the values are \"fare\", index is \"who\" and \"age_group\", and the columns are \"survived\"\n",
    "\n",
    "Hint: set the aggfunc parameter to np.sum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b19d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your pivot_table here:\n",
    "view1 = data.pivot_table(\n",
    "    values = 'fare', # what goes inside the cells\n",
    "    index = ['who', 'age_group'], # table rows\n",
    "    columns = 'survived', # table columns\n",
    "    aggfunc = 'sum') # how each cell is aggregated\n",
    "\n",
    "# Run your table here:\n",
    "view1\n",
    "\n",
    "# The first cell 844.4083 represents multiple rows from our original table.\n",
    "# Each row represeting a child, age 0-9, who did not survive is aggregated in that cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863d61c",
   "metadata": {},
   "source": [
    "### Wide to Long <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> \n",
    "\n",
    "1. Create a table where the columns are \"who\" and the values are \"pclass\"\n",
    "1. Answer the question:  How does this table differ from the pivot_table above?  Specifically, how is \"who\" different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f05a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your table here:\n",
    "view2 = data.pivot(\n",
    "    values = 'fare',  \n",
    "    columns = ['survived', 'who'])\n",
    "\n",
    "\n",
    "# Run your table here:\n",
    "view2\n",
    "\n",
    "# Answer the question here:\n",
    "# there is no aggregation, who is a row instead of a column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854e4b22",
   "metadata": {},
   "source": [
    "### Melt <span style=\"color:dodgerblue;\"> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40521afb",
   "metadata": {},
   "source": [
    "1.  What does **melt** to the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does melt do?\n",
    "\n",
    "#turn columns into rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f586c",
   "metadata": {},
   "source": [
    "2. Melt to your data.  Be sure to store the output in a new variable.  What is the new shape of your table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ee34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your default melt table here with the following syntax:  new_name = pd.melt(data_set)\n",
    "melted = pd.melt(data)\n",
    "# Run your table here:\n",
    "melted\n",
    "# Check the shape of your new table.\n",
    "melted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra step! What does the table actually look like?\n",
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b09f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted.tail()\n",
    "# Each cell from the original dataframe is recorded, with the column name on the left, and the value on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b203e5c",
   "metadata": {},
   "source": [
    "3. Create a melt table where the index variables are \"embarked\", and the values are \"fare\" and \"deck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dddb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your melt table here:\n",
    "melted2 = data.melt(id_vars = 'embarked', value_vars = ['fare', 'deck'])\n",
    "# Run your table here:\n",
    "melted2\n",
    "# Check the shape\n",
    "melted2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c7217",
   "metadata": {},
   "source": [
    "# Optonal Challenges:\n",
    "\n",
    "1. Clean and Explore the table.  \n",
    "    1. How would you handle any missing data?\n",
    "    1. Would you keep all of the columns?\n",
    "    1. Would you want to manipulate any data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left_only = left_join.loc[left_join[\"_merge\"] == [\"left_only\", \"Name\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
